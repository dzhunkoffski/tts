{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7021112,"sourceType":"datasetVersion","datasetId":4036457},{"sourceId":7021231,"sourceType":"datasetVersion","datasetId":4036502},{"sourceId":7021232,"sourceType":"datasetVersion","datasetId":4036501},{"sourceId":7021734,"sourceType":"datasetVersion","datasetId":4037835},{"sourceId":7029987,"sourceType":"datasetVersion","datasetId":4043499},{"sourceId":7030276,"sourceType":"datasetVersion","datasetId":4043709}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/dzhunkoffski/tts.git","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:21:21.922314Z","iopub.execute_input":"2023-11-23T10:21:21.922650Z","iopub.status.idle":"2023-11-23T10:21:24.001215Z","shell.execute_reply.started":"2023-11-23T10:21:21.922622Z","shell.execute_reply":"2023-11-23T10:21:23.999997Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'tts'...\nremote: Enumerating objects: 295, done.\u001b[K\nremote: Counting objects: 100% (295/295), done.\u001b[K\nremote: Compressing objects: 100% (199/199), done.\u001b[K\nremote: Total 295 (delta 147), reused 236 (delta 91), pack-reused 0\u001b[K\nReceiving objects: 100% (295/295), 573.78 KiB | 13.99 MiB/s, done.\nResolving deltas: 100% (147/147), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.environ['WANDB_API_KEY'] = 'YOYR KEY'","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:21:24.003739Z","iopub.execute_input":"2023-11-23T10:21:24.004102Z","iopub.status.idle":"2023-11-23T10:21:24.010017Z","shell.execute_reply.started":"2023-11-23T10:21:24.004070Z","shell.execute_reply":"2023-11-23T10:21:24.008935Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!mkdir tts/tts/waveglow/pretrained_model","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:21:24.011461Z","iopub.execute_input":"2023-11-23T10:21:24.011832Z","iopub.status.idle":"2023-11-23T10:21:24.980779Z","shell.execute_reply.started":"2023-11-23T10:21:24.011801Z","shell.execute_reply":"2023-11-23T10:21:24.978941Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/tts-pretrained-waveglow/waveglow_256channels.pt tts/tts/waveglow/pretrained_model","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:21:24.988221Z","iopub.execute_input":"2023-11-23T10:21:24.992163Z","iopub.status.idle":"2023-11-23T10:21:32.168202Z","shell.execute_reply.started":"2023-11-23T10:21:24.992107Z","shell.execute_reply":"2023-11-23T10:21:32.167121Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install inflect\n!pip install hparams","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:21:32.169580Z","iopub.execute_input":"2023-11-23T10:21:32.169907Z","iopub.status.idle":"2023-11-23T10:21:57.088997Z","shell.execute_reply.started":"2023-11-23T10:21:32.169876Z","shell.execute_reply":"2023-11-23T10:21:57.088015Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting inflect\n  Obtaining dependency information for inflect from https://files.pythonhosted.org/packages/fb/c6/d9feb758be584f729424390af24687d3a4363d968164f94079f83cd536b4/inflect-7.0.0-py3-none-any.whl.metadata\n  Downloading inflect-7.0.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: pydantic>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from inflect) (1.10.12)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from inflect) (4.5.0)\nDownloading inflect-7.0.0-py3-none-any.whl (34 kB)\nInstalling collected packages: inflect\nSuccessfully installed inflect-7.0.0\nCollecting hparams\n  Downloading hparams-0.3.0-py3-none-any.whl (11 kB)\nRequirement already satisfied: typeguard in /opt/conda/lib/python3.10/site-packages (from hparams) (2.13.3)\nInstalling collected packages: hparams\nSuccessfully installed hparams-0.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd tts ; python train.py --config tts/configs/kaggle_fs2.json","metadata":{"execution":{"iopub.status.busy":"2023-11-23T10:21:57.090398Z","iopub.execute_input":"2023-11-23T10:21:57.090683Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/kaggle/working/tts/tts/text/__init__.py:75: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  return s in _symbol_to_id and s is not '_' and s is not '~'\n/kaggle/working/tts/tts/text/__init__.py:75: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n  return s in _symbol_to_id and s is not '_' and s is not '~'\nBROKEN IXS: 209\nBROKEN IXS: 29\nPitch range: 0.0 669.1782457256365\nEnergy range: 2261.755512870478 6363970.314619009\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'glow.WaveGlow' has changed. Saved a reverse patch to WaveGlow.patch. Run `patch -p0 < WaveGlow.patch` to revert your changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose1d' has changed. Saved a reverse patch to ConvTranspose1d.patch. Run `patch -p0 < ConvTranspose1d.patch` to revert your changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. Saved a reverse patch to ModuleList.patch. Run `patch -p0 < ModuleList.patch` to revert your changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'glow.WN' has changed. Saved a reverse patch to WN.patch. Run `patch -p0 < WN.patch` to revert your changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv1d' has changed. Saved a reverse patch to Conv1d.patch. Run `patch -p0 < Conv1d.patch` to revert your changes.\n  warnings.warn(msg, SourceChangeWarning)\n/opt/conda/lib/python3.10/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'glow.Invertible1x1Conv' has changed. Saved a reverse patch to Invertible1x1Conv.patch. Run `patch -p0 < Invertible1x1Conv.patch` to revert your changes.\n  warnings.warn(msg, SourceChangeWarning)\nFastSpeechV2(\n  (phoneme_embedding_layer): Embedding(148, 384, padding_idx=0)\n  (pos_enc): PositionalEncoding()\n  (encoder): ModuleList(\n    (0-3): 4 x FFTBlock(\n      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n      (multihead_attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n      )\n      (lay_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (conv): Sequential(\n        (0): Conv1D(\n          (conv): Conv1d(384, 1024, kernel_size=(3,), stride=(1,), padding=same)\n        )\n        (1): ReLU()\n        (2): Conv1D(\n          (conv): Conv1d(1024, 384, kernel_size=(3,), stride=(1,), padding=same)\n        )\n      )\n      (lay_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (decoder): ModuleList(\n    (0-3): 4 x FFTBlock(\n      (q_proj): Linear(in_features=384, out_features=384, bias=True)\n      (k_proj): Linear(in_features=384, out_features=384, bias=True)\n      (v_proj): Linear(in_features=384, out_features=384, bias=True)\n      (multihead_attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n      )\n      (lay_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (conv): Sequential(\n        (0): Conv1D(\n          (conv): Conv1d(384, 1024, kernel_size=(3,), stride=(1,), padding=same)\n        )\n        (1): ReLU()\n        (2): Conv1D(\n          (conv): Conv1d(1024, 384, kernel_size=(3,), stride=(1,), padding=same)\n        )\n      )\n      (lay_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (variance_adaptor): VarAdaptor(\n    (duration_predictor): FeaturePredictor(\n      (conv1): Conv1D(\n        (conv): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=same)\n      )\n      (lay_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (activasion): ReLU()\n      (conv2): Conv1D(\n        (conv): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=same)\n      )\n      (lay_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (linear): Linear(in_features=384, out_features=1, bias=True)\n    )\n    (length_regulator): LengthRegulator()\n    (pitch_predictor): FeaturePredictor(\n      (conv1): Conv1D(\n        (conv): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=same)\n      )\n      (lay_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (activasion): ReLU()\n      (conv2): Conv1D(\n        (conv): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=same)\n      )\n      (lay_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (linear): Linear(in_features=384, out_features=1, bias=True)\n    )\n    (energy_predictor): FeaturePredictor(\n      (conv1): Conv1D(\n        (conv): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=same)\n      )\n      (lay_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (activasion): ReLU()\n      (conv2): Conv1D(\n        (conv): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=same)\n      )\n      (lay_norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (linear): Linear(in_features=384, out_features=1, bias=True)\n    )\n    (pitch_embedding): Embedding(256, 384)\n    (energy_embedding): Embedding(256, 384)\n  )\n  (mel_linear): Linear(in_features=384, out_features=80, bias=True)\n  (vocoder): WaveGlow(\n    (upsample): ConvTranspose1d(80, 80, kernel_size=(1024,), stride=(256,))\n    (WN): ModuleList(\n      (0-3): 4 x WN(\n        (in_layers): ModuleList(\n          (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n          (1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n          (2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n          (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n          (4): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n          (5): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n          (6): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n          (7): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n        )\n        (res_skip_layers): ModuleList(\n          (0-6): 7 x Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n          (7): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n        )\n        (cond_layers): ModuleList(\n          (0-7): 8 x Conv1d(640, 512, kernel_size=(1,), stride=(1,))\n        )\n        (start): Conv1d(4, 256, kernel_size=(1,), stride=(1,))\n        (end): Conv1d(256, 8, kernel_size=(1,), stride=(1,))\n      )\n      (4-7): 4 x WN(\n        (in_layers): ModuleList(\n          (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n          (1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n          (2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n          (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n          (4): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n          (5): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n          (6): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n          (7): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n        )\n        (res_skip_layers): ModuleList(\n          (0-6): 7 x Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n          (7): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n        )\n        (cond_layers): ModuleList(\n          (0-7): 8 x Conv1d(640, 512, kernel_size=(1,), stride=(1,))\n        )\n        (start): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n        (end): Conv1d(256, 6, kernel_size=(1,), stride=(1,))\n      )\n      (8-11): 4 x WN(\n        (in_layers): ModuleList(\n          (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n          (1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n          (2): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n          (3): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n          (4): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n          (5): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n          (6): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n          (7): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n        )\n        (res_skip_layers): ModuleList(\n          (0-6): 7 x Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n          (7): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n        )\n        (cond_layers): ModuleList(\n          (0-7): 8 x Conv1d(640, 512, kernel_size=(1,), stride=(1,))\n        )\n        (start): Conv1d(2, 256, kernel_size=(1,), stride=(1,))\n        (end): Conv1d(256, 4, kernel_size=(1,), stride=(1,))\n      )\n    )\n    (convinv): ModuleList(\n      (0-3): 4 x Invertible1x1Conv(\n        (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n      )\n      (4-7): 4 x Invertible1x1Conv(\n        (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n      )\n      (8-11): 4 x Invertible1x1Conv(\n        (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n      )\n    )\n  )\n)\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdzhunkoffski\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/tts/wandb/run-20231123_102341-ugwbwg11\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexalted-sky-115\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dzhunkoffski/tts\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dzhunkoffski/tts/runs/ugwbwg11\u001b[0m\ntrain: 100%|████████████████████████████████████| 20/20 [00:25<00:00,  1.27s/it]\nval: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  4.56it/s]\n    epoch          : 1\n    loss           : 36.513771057128906\n    grad norm      : 1.0\n    DurationLossMetric: 1.9422736167907715\n    PitchLossMetric: 13.114068031311035\n    EnergyLossMetric: 130.6648406982422\n    MelLossMetric  : 27.139497756958008\n    val_loss       : 23.37935161590576\n    val_DurationLossMetric: 0.9187073707580566\n    val_PitchLossMetric: 7.259891510009766\n    val_EnergyLossMetric: 106.7562026977539\n    val_MelLossMetric: 17.09461212158203\nSaving current best: model_best.pth ...\ntrain: 100%|████████████████████████████████████| 20/20 [00:18<00:00,  1.07it/s]\nval: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  5.18it/s]\n    epoch          : 2\n    loss           : 20.9601993560791\n    grad norm      : 0.9999999403953552\n    DurationLossMetric: 0.8979254961013794\n    PitchLossMetric: 6.470158576965332\n    EnergyLossMetric: 95.33616638183594\n    MelLossMetric  : 15.326298713684082\n    val_loss       : 21.783026695251465\n    val_DurationLossMetric: 0.7093827724456787\n    val_PitchLossMetric: 6.559350967407227\n    val_EnergyLossMetric: 103.015380859375\n    val_MelLossMetric: 15.92626953125\nSaving current best: model_best.pth ...\ntrain: 100%|████████████████████████████████████| 20/20 [00:21<00:00,  1.05s/it]\nval: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  5.41it/s]\n    epoch          : 3\n    loss           : 21.410490036010742\n    grad norm      : 0.9999999403953552\n    DurationLossMetric: 0.6265729069709778\n    PitchLossMetric: 6.279952526092529\n    EnergyLossMetric: 99.35649108886719\n    MelLossMetric  : 15.796431541442871\n    val_loss       : 18.347652435302734\n    val_DurationLossMetric: 0.4679737091064453\n    val_PitchLossMetric: 6.156708717346191\n    val_EnergyLossMetric: 98.20611572265625\n    val_MelLossMetric: 12.865888595581055\nSaving current best: model_best.pth ...\ntrain: 100%|████████████████████████████████████| 20/20 [00:22<00:00,  1.11s/it]\nval: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  5.36it/s]\n    epoch          : 4\n    loss           : 19.530860900878906\n    grad norm      : 1.0\n    DurationLossMetric: 0.4991441071033478\n    PitchLossMetric: 6.44681453704834\n    EnergyLossMetric: 102.9107666015625\n    MelLossMetric  : 13.785181045532227\n    val_loss       : 14.536138534545898\n    val_DurationLossMetric: 0.37932202219963074\n    val_PitchLossMetric: 6.227717399597168\n    val_EnergyLossMetric: 99.94300842285156\n    val_MelLossMetric: 9.002358436584473\nSaving current best: model_best.pth ...\ntrain:  25%|█████████▎                           | 5/20 [00:16<00:25,  1.73s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}